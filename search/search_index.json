{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TL;DR DevOps","text":"<p>DevOps is a set of practices, tools, and a cultural philosophy that automate and integrate the processes between software development and IT teams.</p> <p>DevOps is a methodology that promotes collaboration and automation between development (Dev) and IT operations (Ops) teams. It aims to streamline software development and delivery, automate repetitive tasks, and enhance code quality through continuous integration, continuous delivery, and cultural shifts, ultimately resulting in faster, more reliable software releases.</p>"},{"location":"#devops-lifecycle","title":"DevOps lifecycle","text":"<ol> <li>Plan</li> <li>Code</li> <li>Build</li> <li>Test</li> <li>Release</li> <li>Deploy</li> <li>Operate</li> <li>Monitor</li> </ol>"},{"location":"#ides-editors","title":"IDEs / Editors","text":"<ul> <li> Visual Studio Code</li> <li> GitHub Copilot</li> </ul>"},{"location":"#source-control","title":"Source control","text":"<ul> <li> Git</li> </ul>"},{"location":"#command-line","title":"Command line","text":"<ul> <li> Linux OS</li> <li> Bash</li> <li> PowerShell</li> <li> Vim</li> </ul>"},{"location":"#programming-languages","title":"Programming languages","text":"<ul> <li> Python</li> <li>Go</li> <li>.NET / ASP.NET</li> <li>JavaScript</li> </ul>"},{"location":"#cicd","title":"CI/CD","text":"<p>Continuous Integration and Continuous Delivery (CI/CD) is the method to frequently deliver apps to customers by introducing automation into the stages of app development.</p> <ul> <li> GitHub Actions</li> <li> GitHub Codespaces</li> </ul>"},{"location":"#ci","title":"CI","text":"<ol> <li>Automate the Build</li> <li>Introduce Automation test (units tests, integration, ...)</li> <li>Linting</li> <li>Security / Scanning</li> </ol> <p>Based on the workflow (like GitHub Flow &gt; Git Flow) add Pull/Merge Request to be reviewed and approved by other collaborators.</p>"},{"location":"#cd","title":"CD","text":"<ul> <li>Environments: Dev -&gt; Staging -&gt; Prod</li> <li>User feedback (Blue/Green, Canary, ...)</li> </ul>"},{"location":"#containers","title":"Containers","text":"<ul> <li> Docker</li> </ul>"},{"location":"#containers-orchestation","title":"Containers orchestation","text":"<ul> <li> Kubernetes</li> </ul>"},{"location":"#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>Infrastructure as Code (IaC) is the managing and provisioning of infrastructure through code instead of through manual processes.</p> <p>Tools:</p> <ul> <li> Terraform</li> </ul>"},{"location":"#configuration-as-code","title":"Configuration as Code","text":"<p>Sometimes also called Software Configuration Management.</p> <ul> <li> Ansible</li> </ul>"},{"location":"#networking","title":"Networking","text":"<ul> <li> CIDR</li> </ul>"},{"location":"#cloud-computing","title":"Cloud Computing","text":"<ul> <li> Azure</li> <li>AWS</li> <li>GCP</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li> MkDocs</li> <li> Jekyll</li> </ul>"},{"location":"#security","title":"Security","text":"<ul> <li>Checkov</li> <li>CodeQL</li> <li>HashiCorp Vault</li> </ul>"},{"location":"#monitoring","title":"Monitoring","text":"<ul> <li>Graphana</li> <li>Prometheus</li> <li>ELK Stack</li> </ul>"},{"location":"#testing","title":"Testing","text":""},{"location":"#linting","title":"Linting","text":""},{"location":"#miscellany","title":"Miscellany","text":"<ul> <li> Databricks</li> </ul>"},{"location":"#know-more","title":"Know more","text":"<ul> <li>GitHub - Libre DevOps</li> <li>GitHub - TL;DR DevOps</li> </ul>"},{"location":"#sponsorship","title":"Sponsorship","text":""},{"location":"ansible/","title":"Ansible","text":""},{"location":"azure/","title":"Azure","text":""},{"location":"azure/#architecture","title":"Architecture","text":"<ul> <li>Browse Azure Architectures examples</li> </ul>"},{"location":"azure/#technology-choices-for-azure-solutions","title":"Technology choices for Azure solutions","text":"<ul> <li>Technology choices for Azure solutions</li> </ul>"},{"location":"azure/#decisions-tree","title":"Decisions tree","text":"<ul> <li>Choose an Azure compute service</li> <li>Load-balancing options</li> </ul>"},{"location":"azure/#certifications","title":"Certifications","text":""},{"location":"azure/#code","title":"Code","text":"<ul> <li> aztfexport example</li> <li> R access Azure identity</li> </ul>"},{"location":"azure/#tools","title":"Tools","text":"<ul> <li>Continuous Cloud Optimization Power BI Dashboard GitHub Project</li> </ul>"},{"location":"bash/","title":"Linux commands Cheat Sheet","text":""},{"location":"bash/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"<ul> <li>Ctrl+a : Begin of command line</li> <li>Ctrl+e : End of command line</li> <li>Ctrl+w : Delete word of command line</li> <li>Ctrl+u : Delete full line of command line</li> <li>Ctrl+r : Search in the command history</li> <li>Ctrl+l : Clear console</li> <li>F11 :  Full screen</li> <li>Ctrl+Shift++ : Increase font size</li> <li>Ctrl+Shift+- : Descrease font size</li> </ul>"},{"location":"bash/#move-in-console","title":"Move in console","text":"<pre><code># Show the manual for command\nman command\n\n# Show the history of the commands executed\nhistory\n\n# Uses the bang (!) to refer to the id of the command in history\n!&lt;history_number&gt;\n\n# Repeat the last command executed\n!!\n\n# Delete all output and restart console\nreset\n\n# Show the output of a command in a table format\ncommand | column -t\n\n# Stack of directories to save navigation\npushd /path/file\npopd /path/file\n</code></pre>"},{"location":"bash/#file-commands","title":"File commands","text":"<pre><code># Formatted listing with hidden files\nls -la\n\n# Change directory to dir\ncd\n\n# Change directory to home\ncd\ncd ~\n\n# Back to previous directory\ncd -\n\n# Create a directory dir\nmkdir dir\n\n# Force remove directory dir\nrm -rf dir\n\n# Copy dir1 to dir2\ncp -r dir1 dir2\n\n# Rename/move file1 to file2\nmv file1 file2\n\n# Create symbolic link to file\nln -s file link\n\n# Create or update file\ntouch file\n\n# Place standard input into file\ncat &gt; file\n\n# Output the cotents of file\nmore file\n\n# Output the first lines of file\nhead file\n\n# Output the last lines of file\ntail file\n\n# Output the contents of file as it grows, starting with the last 10 lines\ntail -f file\n\n# Set the size of the file to 0, so it delets all of its content\ntruncate -s 0 file\n\n# Count words/lines in a file\nwc\n</code></pre>"},{"location":"bash/#file-permissions","title":"File Permissions","text":"<pre><code># Change the mode of access `chmod OPTIONS {u,g,o}{+,-,=}{r,w,x}`\n# User (u), Group (g), Others (o)\n# Read (r,4), Write (w, 2), Execute (x, 1) \nchmod 777 file\nchmod u=rwx filename\nchmod -r +x file\n\n# change the file owner and/or group\nchown owner:group file\nchown -r owner:group file\n</code></pre>"},{"location":"bash/#process-management","title":"Process Management","text":"<pre><code># Display your currently active processes\nps\n\n# Display all running processes\ntop\nhtop\n\n# Kill process id PID\nkill &lt;PID&gt;\n\n# Kill al processes named proc\nkillall proc\n\n# \"Minimaze\" send to the background\nctrl + z\n\n# List stopped or background jobs; resume a stopped job in the background\nbg\n\n# Brings the most revent job to foreground\nfg\n\n# Brings job n to the foregroun \nfg n\n\n# Run a command immune to hangups, even when the parent terminal is closed\nnohup command\n\n# Process starts in the background\ncommand &amp;\n\n# Process starts in the background and the process will not be killed when closing the terminal\nnohup command &amp;\n</code></pre>"},{"location":"bash/#ssh","title":"SSH","text":"<pre><code># Connect to host as user\nssh user@host\n\n# Connect to host on port as user\nssh -p port user@host\n\n# Add your key to host for user to enable a keyed or passwordless login\nssh-copy-id user@host\n\n# Copies files between hosts on a network\nscp adm-dumitrux@10.0.0.10:/home/adm-dumitrux/ dumitrux@10.0.0.20:/home/dumitrux\n\n\n# Copies files between hosts on a network; selects the private key for authentication\nscp adm-dumitrux@10.0.0.10:/home/adm-dumitrux/ dumitrux@10.0.0.20:/home/dumitrux -i ~/.ssh/mytest.key\n</code></pre>"},{"location":"bash/#searching","title":"Searching","text":"<pre><code># Search for pattern in files\ngrep pattern files\n\n# Search recursively for pattern in dir\ngrep -r pattern dir\n\n# Search for pattern in the output of command\ncommand | grep pattern\n\n# Find all instances of file\nlocate file\n</code></pre>"},{"location":"bash/#system-info","title":"System info","text":"<pre><code># Show the current date and time\ndate\n\n# Show this month's calendar\ncal\n\n# Show current uptime\nuptimw\n\n# Display who is online\nw\n\n# Who you are loggin in as\nwhoami\n\n# Display information about user\nfinger user\n\n# Show kernel information\nuname -o\n\n# CPU information\ncat /proc/cpuinfo\n\n# Memory information\ncat /proc/meminfo\n\n# Show disk usage\ndf\n\n# Show directory space usage\ndu\n\n# Estimate file space usage; sc: display only a total; h: human readable format\ndu -sch | sort -h\n\n# Show memory and swap usage\nfree\n\n# Show possible locations of app\nwhereis app\n\n# Show which app will be run by default\nwhich app\n</code></pre>"},{"location":"bash/#network","title":"Network","text":"<pre><code># Ping host and output results\nping host\n\n# Get whois info for domain\nwhois domain\n\n# Download file\nwget file\n\n# DNS lookup utility\ndig google.com\ndig google.com @dns_ip\n\n# Print the route packets trace to network host\ntraceroute -4 google.com\n\n# Query Internet name servers interactively\nnslookup google.com\n</code></pre>"},{"location":"bash/#compression","title":"Compression","text":"<pre><code># Create a file.tar containing files\ntar cf file.tar files\n\n# Extract the files from file.tar\ntar xf file.tar\n\n# Create a tar using gzip\ntar czf file.tar.gz files\n\n# Extract a tar using gzip with verbose output\ntar xzfv file.tar.gz\n</code></pre>"},{"location":"bash/#miscellany","title":"Miscellany","text":"<pre><code># Edit the user session bash to add the date on the history commands output\nvim ~/.bashrc\n&gt; HISTTIMEFORMAT=\"%T-%m-%d %T \"\n\n# Not useful, just looks cool\ncmatrix\n</code></pre>"},{"location":"bash/#references","title":"References","text":"<ul> <li>Pattern Matching In Bash</li> </ul>"},{"location":"databricks/","title":"Databricks useful commands","text":""},{"location":"databricks/#bash-script-in-devops-release","title":"Bash script in DevOps Release","text":"<pre><code>databricks_path=\"$(System.DefaultWorkingDirectory)/_&lt;Repo_name&gt;/databricks-scripts/\"\ndatabricks_url=\"https://&lt;databricks_id&gt;.azuredatabricks.net\"\n</code></pre>"},{"location":"databricks/#get-azure-ad-tokens-for-the-service-principal","title":"Get Azure AD tokens for the service principal","text":"<pre><code>access_token=$(curl -X POST -H 'Content-Type: application/x-www-form-urlencoded' \\\nhttps://login.microsoftonline.com/&lt;tenant_id&gt;/oauth2/v2.0/token \\\n-d 'client_id=$(spclientid)' \\\n-d 'grant_type=client_credentials' \\\n-d 'scope=&lt;scope&gt;.default' \\\n-d 'client_secret=$(spclientsecret)' \\\n| jq -r .access_token)\n</code></pre>"},{"location":"databricks/#use-the-service-principals-azure-ad-access-token-to-access-the-databricks-rest-api","title":"Use the service principal\u2019s Azure AD access token to access the Databricks REST API","text":"<pre><code>curl -X POST \\\n-H \"Authorization: Bearer $access_token\" \\\n$databricks_url/api/2.0/preview/scim/v2/ServicePrincipals \\\n-H 'Content-type: application/scim+json' \\\n-d @\"$databricks_path/create-service-principal.json\"\n</code></pre>"},{"location":"databricks/#create-a-cluster-with-the-configuration-in-create-clusterjson","title":"Create a cluster with the configuration in create-cluster.json","text":"<pre><code>curl -X POST \\\n-H \"Authorization: Bearer $access_token\" \\\n$databricks_url/api/2.0/clusters/create \\\n-d @\"$databricks_path/create-cluster.json\"\n</code></pre>"},{"location":"databricks/#upload-the-mount-script-into-databricks-shared-workspace","title":"Upload the mount script into Databricks Shared workspace","text":"<pre><code>curl --request POST \\\n-H \"Authorization: Bearer $access_token\" \\\n$databricks_url/api/2.0/workspace/import \\\n--header 'Content-Type: multipart/form-data' \\\n--form path=/Shared/mount-dir \\\n--form content=@\"$databricks_path/mount-dir.py.zip\"\n</code></pre>"},{"location":"databricks/#list-the-clusters-to-find-a-specific-one","title":"List the clusters to find a specific one","text":"<pre><code>cluster_id=$(curl -X GET \\\n-H \"Authorization: Bearer $access_token\" \\\n$databricks_url/api/2.0/clusters/list \\\n| jq '.clusters[] | select(.cluster_name==\"Cluster\")' | jq -r .cluster_id)\n\necho $cluster_id\n\njq -n --arg existing_cluster_id $cluster_id '{ \"run_name\": \"Run mount-dir\", \"existing_cluster_id\": $existing_cluster_id, \"notebook_task\": { \"notebook_path\": \"/Shared/mount-dir\" } }' &gt; \"$databricks_path/run-job.json\"\n\ncat \"$databricks_path/run-job.json\"\n\ncurl -X POST \\\n-H \"Authorization: Bearer $access_token\" \\\n$databricks_url/api/2.0/jobs/runs/submit \\\n--data @\"$databricks_path/run-job.json\"\n\ncurl -X GET \\\n-H \"Authorization: Bearer $access_token\" \\\n$databricks_url/api/2.0/jobs/runs/list\n</code></pre>"},{"location":"git/","title":"Git","text":""},{"location":"git/#useful-resources","title":"Useful resources","text":"<ul> <li>Git official documentation</li> <li>GitHub Cheat Sheet</li> <li>Learn Git Branching interactively</li> <li>Altassian Git tutorials</li> <li>Git Immersion</li> </ul>"},{"location":"git/#configure","title":"Configure","text":"<p>Set up user information for all your local repositories.</p> <ul> <li><code>git config --global user.name  \u201c[name]\u201d</code>: Specify the name associated with your commit transactions.</li> <li><code>git config --global user.name</code>: View the currently configured name.</li> <li><code>git config --global user.email \u201c[email]\u201d</code>: Define the email address linked to your commit transactions, which will be made public.</li> <li><code>git config --global user.email</code>: View the currently configured email address.</li> <li><code>git config --global color.ui true</code>: Enable helpful colorization of command-line output.</li> <li><code>git config --global --list</code>: visplay the current configuration settings.</li> <li><code>git help</code>: Provide information on how Git functions, or specify a command for detailed help.</li> </ul>"},{"location":"git/#create-repositories","title":"Create Repositories","text":"<p>Initiate a new repository or retrieve one from an existing URL.</p> <ul> <li><code>git init</code>: Commence a project and have Git start monitoring it.</li> <li><code>git init [project-name]</code>: Establish a new local repository with the given name.</li> <li><code>git clone [url]</code>: Download a project along with its complete version history.</li> </ul>"},{"location":"git/#stage-changes","title":"Stage Changes","text":"<p>Review modifications and prepare them for a commit transaction.</p> <ul> <li><code>git status</code>: List all new or altered files that need to be committed.</li> <li><code>git diff</code>: Display file differences that have not been staged yet.</li> <li><code>git add [file]</code>: Snapshot the file to prepare it for versioning.</li> <li><code>git add -A</code>: : Add all files.</li> <li><code>git diff --staged</code>: Exhibit file differences between the staging area and the latest version.</li> <li><code>git reset [file]</code>: Unstage the file while preserving its contents.</li> <li><code>git commit -m \"[descriptive message]\"</code>: Permanently record file snapshots in the version history.</li> <li><code>git commit</code>: Open the default text editor for writing the commit message.</li> </ul>"},{"location":"git/#group-changes","title":"Group Changes","text":"<p>Name a series of commits and combine completed efforts.</p> <ul> <li><code>git branch</code>: List all branches in the current repository.</li> <li><code>git branch [branch-name]</code>: Create a new branch.</li> <li><code>git checkout [branch-name]</code>: Switch to the specified branch and update the active directory.</li> <li><code>git merge [branch]</code>: Combine the history of the specified branch with the current branch.</li> <li><code>git branch -d [branch-name]</code>: Delete the specified branch.</li> <li><code>git push -u origin [branch-name]</code>: Push your branch to the remote repository.</li> </ul>"},{"location":"git/#rename-file-refactoring","title":"Rename File Refactoring","text":"<p>Relocate and remove versioned files.</p> <ul> <li><code>git rm --cached [file]</code>: Remove the file from version control, but keep it locally.</li> <li><code>git rm [file]</code>: Delete the file from the working directory and stage the deletion.</li> <li><code>git mv [file-original] [file-renamed]</code>: Rename the file and stage it for commit.</li> </ul>"},{"location":"git/#suppress-tracking","title":"Suppress Tracking","text":"<p>Exclude temporary files and paths. Adding an entry to the <code>.gitignore</code> file in the root directory.</p> <ul> <li><code>git ls-files --other --ignored --exclude-standard</code>: List all ignored files in this project</li> </ul>"},{"location":"git/#save-stashes","title":"Save Stashes","text":"<p>Store and recover incomplete changes.</p> <ul> <li><code>git stash</code>: Temporarily preserve all modified tracked files.</li> <li><code>git stash list</code>: List all sets of saved changes.</li> <li><code>git stash pop</code>: Apply the most recently saved changes.</li> <li><code>git stash drop</code>: Discard the most recently saved set of changes.</li> </ul>"},{"location":"git/#review-history","title":"Review History","text":"<p>Navigate through and inspect the evolution of project files.</p> <ul> <li><code>git log</code>: List the version history for the current branch.</li> <li><code>git log --follow [file]</code>: List the version history for the file, including renames.</li> <li><code>git diff [first-branch]...[second-branch]</code>: Show content differences between two branches.</li> <li><code>git show [commit]</code>: Display metadata and content changes for the specified commit.</li> </ul>"},{"location":"git/#redo-commits","title":"Redo Commits","text":"<p>Undo errors and craft a replacement history.</p> <ul> <li><code>git reset [commit]</code>: Reverse all commits made after [commit], while preserving changes locally.</li> <li><code>git reset --hard [commit]</code>: Discard the entire history and return to the specified commit.</li> </ul>"},{"location":"git/#sync-changes","title":"Sync Changes","text":"<p>Register a repository bookmark and exchange version history.</p> <ul> <li><code>git fetch [bookmark]</code>: Download the entire history from the repository bookmark.</li> <li><code>git merge [bookmark]/[branch]</code>: Combine the bookmarked branch with the current local branch.</li> <li><code>git push [alias] [branch]</code>: Upload all commits from the local branch to GitHub.</li> <li><code>git pull</code>: Download the bookmarked history and incorporate changes.</li> </ul>"},{"location":"git/#first-project","title":"First Project","text":"<ul> <li><code>git log</code>: List all commits along with their respective information.</li> <li><code>git log &gt; commits.txt</code>: Create a file with the content of git log.</li> <li><code>git checkout 'commit code'</code>: Navigate between commits and branches. Using 'master' instead of the code moves to the latest commit.</li> <li><code>git reset</code>: Similar to checkout, but it removes commits.</li> <li><code>git reset --soft 'commit code'</code>: Delete a commit without affecting the working area (no impact on the code).</li> <li><code>git reset --mixed</code>: Clear the staging area without affecting the working area.</li> <li><code>git reset --hard</code>: Discard everything in the commit.</li> </ul>"},{"location":"git/#branches-and-merges","title":"Branches and Merges","text":"<ul> <li>Head: The commit you are currently on.</li> <li>Branches: The project's timeline. When you create a new branch, it inherits from the previous one (usually Master), and from that point onwards, commits are only saved to this branch.</li> <li>Main/Master Branch: Created by default when using git init, this is where commits are made.</li> <li><code>git branch</code>: Show all branches.</li> <li><code>git branch 'Branch Name'</code>: Create a new branch from Head.</li> <li><code>git checkout 'Branch Name'</code>: Besides navigating between commits, it also allows you to switch between branches.</li> <li><code>git checkout -b 'Branch Name'</code>: Create a branch and switch to it.</li> <li><code>git branch -D 'Branch Name'</code>: Delete a branch.</li> <li><code>git merge 'Branch Name'</code>: The selected branch is absorbed by the current branch.</li> <li><code>git branch -a</code>: Show all branches, including hidden ones.</li> </ul>"},{"location":"git/#repository-managers-github-gitlab-etc","title":"Repository Managers (GitHub, GitLab, etc.)","text":"<ul> <li><code>git remote</code>: Link the local project to a remote project.</li> <li><code>git remote add origin \u2018https\u2019</code>:</li> <li><code>git remote -v</code>: Confirm the link.</li> <li><code>git remote remove origin</code>: Remove the link.</li> <li><code>git push</code>: Send changes (commits) from your PC to GitHub.</li> <li><code>git push origin master</code>: Upload the master branch.</li> <li><code>git push origin 'Branch Name'</code>: Upload a branch, creating a new one on GitHub.</li> </ul>"},{"location":"git/#github","title":"GitHub","text":"<ul> <li>Issues: Suggestions, comments to others, things to fix in your own code, etc.</li> <li>Milestones: Groups of issues that apply to a project, feature, or time period.</li> <li>Labels: A way to categorize different types of issues based on their problem type.</li> </ul>"},{"location":"git/#tags","title":"Tags","text":"<ul> <li>Tags: Specific points in your project's history used to mark a certain version.</li> <li><code>git commit --amend -m \"New commit name\"</code>: Changes the name of the current commit.</li> <li><code>git push origin master -f</code>: Forces the push to upload changes even if there are no code changes but there are new commits.</li> <li><code>git tag -a v1.0 -m \"Message\"</code>: Annotated tags, stored as complete objects within Git and contain more information. The version can be chosen as desired, such as v0.8 for the 8th commit, for example.</li> <li><code>git tag v1.0</code>: Lightweight tags, a simpler way to create tags with less information.</li> <li><code>git tag -a v1.0 -m \"Message\" '[SHA]'</code>: By adding the SHA code, you can specify where the tag will be applied.</li> <li><code>git push origin v1.0</code>: Pushes the selected version of the tags.</li> <li><code>git push origin --tags</code>: Uploads all tags.</li> <li><code>git show v1.0</code>: Displays information about that version.</li> </ul>"},{"location":"git/#workflows","title":"Workflows","text":"<ul> <li> <p>Workflow: A workflow for managing your own projects, working in teams, or with third parties. The above information covers personal projects. The following information is about team projects (organizations):</p> </li> <li> <p><code>git fetch origin</code>: Fetches changes from the remote repository to origin/master.</p> </li> <li><code>git merge origin/master</code>: Merges origin/master branch into the current branch.</li> <li>Fast-forward: Changes do not conflict.</li> <li>Auto-merging: Changes conflict with changes made by others in the group.</li> <li><code>git push origin master</code>: Uploads changes.</li> </ul> <p>For projects with third parties, where you are not an owner or collaborator but want to participate:</p> <ul> <li>Fork: Clones the original or main repository, unlike Git. Now you'll have one more hidden branch. In addition to 'origin,' you will have 'upstream' (there may be more; check with <code>git branch -a</code>), 'upstream/master,' and 'origin/master.' Fork when you want to contribute to the code.</li> <li>First, fork the project on GitHub, then download the project from your fork's https, edit it.</li> <li><code>git fetch upstream</code></li> <li><code>git fetch origin</code></li> </ul>"},{"location":"git/#github-pages","title":"GitHub Pages","text":"<p>Websites for you and your projects. You can generate a website from your organization or project.</p> <p>For your user:</p> <ol> <li>Create a repository named username.github.io.</li> <li><code>git clone</code> it.</li> <li>Create web code.</li> <li>Upload changes to GitHub (<code>git push...</code>). Once done, you'll have the domain: username.github.io. Whatever you have in the repository is what will appear on the domain.</li> </ol> <p>For a project:</p> <ol> <li>Create a repository.</li> <li><code>git clone</code> it and create a 'gh-pages' branch (git branch gh-pages).</li> <li>Create web code.</li> <li>Upload changes to GitHub (<code>git push...</code>). Everything in the 'gh-pages' branch will be on your domain: username.github.io/repositoryname.</li> </ol>"},{"location":"git/#deployment","title":"Deployment","text":"<p>Only if you have a server. SSH allows easy connection to a server or servers without entering a password each time.</p> <p>With ssh-keygen, you generate a public and private key pair. To connect to the server ssh <code>root@domain.com</code>, with the domain or IP if you don't have a domain yet.</p> <p><code>git pull</code>: Equivalent to <code>git fetch</code> + <code>git merge</code>.</p>"},{"location":"git/#hooks","title":"Hooks","text":"<p>Mechanisms to trigger scripts when certain actions occur.</p> <ul> <li>post-commits: Automatically execute commands when git commit -m \"Message\" is executed.</li> <li>post-checkout</li> <li>post-merge</li> <li>post-rewrite</li> </ul> <p>In the .git folder, you'll find a folder called 'hooks,' and inside, some pre-made hooks. To create a hook, for example, <code>touch post-commit</code>, then <code>nano post-commit</code> to write the content.</p> <p>Content:</p> <pre><code>#!/bin/sh  # Indicates it's a shell script\ngit push origin branch-or-master\nssh root@domain.com 'bash -s' &lt; deployment.sh  # Connects to the server and executes the shell\n</code></pre> <p>Finally, give commit privileges: <code>chmod +x post-commit</code>. Now create a deployment file: <code>touch deployment.sh</code>.</p> <p>deployment.sh:</p> <pre><code>#!/bin/sh\ncd directory  # Moves to the directory\ngit pull origin branch-or-master\nsudo service ghost restart  # Restarts the server, Ghost API\n</code></pre>"},{"location":"git/#steps","title":"Steps","text":"<pre><code># 1. Init\ngit init\n\n# 2. Add changes\ngit add -A\n\n# 3. Check added files\ngit status\n\n# 4. Commit\ngit commit -m \"Message\"\n\n# 5. Check commits\ngit log\n\n# 6. Checkout\ngit checkout 'commit sha'\n\n# 7. Checkout master\ngit checkout master\n\n# 8. Reset (soft)\ngit reset --soft 'commit sha'\n\n# 9. Create branch\ngit branch Branch\n\n# 10. Checkout branch\ngit checkout Branch1\n\n# 11. Make changes in Branch1\n\n# 12. Checkout master \ngit checkout master \n\n# 13. We are on master, which is the branch that will absorb Branch1\ngit merge Branch1 \n\n# 14. Delete Branch1\ngit branch -D Branch1\n\n# 15. GitHub\n\n# 16. Create repository on GitHub, folder and repository better have the same name\n\n# 17. Add remote origin\ngit remote add origin 'https'\n\n# 18. To check\ngit remote -v\n\n# 19. Download, clone, and update\ngit fetch origin\ngit clone 'https' \ngit pull origin master\n\n# 20. To remove the link between the folder and GitHub, if needed\ngit remote remove origin\n\n# 21. Push from PC to GitHub\ngit push origin master\n\n# 22. Upload branch from PC to GitHub\ngit push origin Branch1\n\n# 23. To delete a branch on GitHub, it must be done from the website\n\n# 24. Issues, milestones, and labels from GitHub, to \n\n# 25. Tags (version tags)\n\n# 26. Commit number 8\ngit tag -a v0.8 -m \"Version 0.8 of our project\"\n\n# 27. Code of the second commit\ngit tag -a v0.2 -m \"Version 0.2 of our project\" 'commit sha'\n\n# 28. Push v0.8 to GitHub\ngit push origin v0.8\n\n# 29. Workflows\n\n# 30. Communities\n\n# 31. Show hidden branches 'remotes/origin/master'\ngit branch -a\n\n# 32. Fetch to upload to origin/master\ngit fetch origin\n\n# 33. Merge origin/master\ngit merge origin/master\n\n# 34. Projects with third parties (fork)\n\n# 35. upstream/master branch is the original repository from which you fork\ngit fetch upstream\n\n# 36. origin/master branch is your repository, a clone of the original\ngit fetch origin\n\n# 37. Finally, create a new pull request on GitHub\n\n# 38. GitHub Pages (create a project)\n\n# 39. Create 'gh-pages' branch\n</code></pre>"},{"location":"git/#versioning","title":"Versioning","text":"<p>Semantic Versioning 2.0.0</p>"},{"location":"github-codespaces/","title":"GitHub Codespaces","text":"<ul> <li>GitHub Codespaces overview</li> <li>GitHub - Introduction to dev containers</li> <li>Personalizing GitHub Codespaces for your account</li> </ul> <p>To see all the languages, runtimes, and tools that are included use the command:  <code>devcontainer-info content-url</code></p> <p>Check:</p> <ul> <li>overrideFeatureInstallOrder</li> <li>devcontainers/images</li> </ul>"},{"location":"github-codespaces/#development-containers","title":"Development Containers","text":"<ul> <li>Dev Container - Available Features</li> <li>Dev Container - Specification</li> <li>Dev Container - Metadata reference</li> </ul>"},{"location":"github-codespaces/#predefined","title":"Predefined","text":""},{"location":"github-codespaces/#custom","title":"Custom","text":"<p>Use a Dockerfile or Docker Compose file</p>"},{"location":"github-codespaces/#template-repos","title":"Template Repos","text":"<ul> <li>GH - Dev Container Templates</li> </ul>"},{"location":"github-codespaces/#starter","title":"Starter","text":"<ul> <li>GH - A template explaining how to author custom dev container Templates</li> <li>GH - A bootstrap repo for self-authoring Dev Container Features</li> </ul>"},{"location":"github-copilot/","title":"GitHub Copilot","text":""},{"location":"github-copilot/#usage","title":"Usage","text":""},{"location":"github-copilot/#examples","title":"Examples","text":"<p>GIFs</p>"},{"location":"linux/","title":"Linux OS","text":""},{"location":"linux/#linux-file-system-directories-explained","title":"Linux File System - Directories explained","text":"<p>Here are the most important root directories and their purpose explained</p> <p><code>/bin</code> Contains binaries essential for the system to boot and perform basic functions. Programs like bash, login, etc reside in here. Do not modify anything in it.</p> <p><code>/boot</code> Contains the core assets needed to boot the system, ie, Bootloader, Linux Kernel Image, etc. Do not modify anything in it.</p> <p><code>/proc</code> Virtual filesystem maintained by the Kernel in order to run all processes. Don\u2019t change anything in this dir. But you can look around. Every process has a corresponding directory inside it (named after process ID) where you get lots of information about it.</p> <p><code>/var</code> Contains files that are of variable size/content. Eg- All log files are stored inside /var/log by convention. Eg- Web Servers commonly store frontend assets in /var/www/html.</p> <p><code>/mnt</code> By convention, all devices manually mounted on to the system are mounted inside this directory.</p> <p><code>/media</code> Used for automatic mounting of devices such as USB drive.</p> <p><code>/dev</code> Contains files for all devices mounted on to your system. Eg- When you mount a new EBS volume to your linux-based EC2 instance, you\u2019d usually see the device as \"/dev/sda1\". Eg- You may have seen Bash commands that send output to \"/dev/null\" to simply drop it.</p> <p><code>/etc</code> Contains System-wide configurations &amp; Scripts that run during boot/initialization. All files are text-only so they\u2019re human readable.</p> <p><code>/tmp</code> All temporary files are stored in this directory. It generally gets cleaned out when you reboot your system. Do not store any important data in /tmp. You will likely lose it.</p> <p><code>/lib</code> Contains all the libraries required by programs in /bin. A variation, /usr/lib, may contain libraries for user-space programs</p> <p><code>/root</code> Home directory of the root user in Linux. As a normal user, you may not have access to this directory at all.</p> <p><code>/usr</code> Contains all programs directly used by Linux users. Try exploring /usr/bin. What do you see?</p> <p><code>/home</code> Contains a home folder for each regular user on the system. If you are \u201cben\u201d, then there will be a \u201c/home/ben\u201d directory on the system that you control. But you may or may not be able to access other users' home directories depending on your permissions.</p>"},{"location":"linux/#tls-certificates","title":"TLS Certificates","text":"<p>Formerly known as SSL certificates, TLS certificates are used to secure communication between a client and a server. They are used to encrypt the data being sent between the two parties, preventing third parties from reading the data.</p> <p>Free certificates at Let's Encrypt.</p>"},{"location":"networking/","title":"Networking","text":""},{"location":"networking/#tools","title":"Tools","text":"<ul> <li>ipify API</li> <li>IP Subnet Calculator</li> <li>DNS Propagation Checker</li> <li>Visual Subnet Calculator (Azure Edition)</li> </ul>"},{"location":"powershell/","title":"PowerShell","text":""},{"location":"powershell/#scripts","title":"Scripts","text":"<p>Iterate through files in a directory</p> <pre><code>Get-ChildItem \".\" -Filter *.log | \nForeach-Object {\n    $content = Get-Content $_.FullName\n\n    #filter and save content to the original file\n    $content | Where-Object {$_ -match 'step[49]'} | Set-Content $_.FullName\n\n    #filter and save content to a new file \n    $content | Where-Object {$_ -match 'step[49]'} | Set-Content ($_.BaseName + '_out.log')\n}\n</code></pre>"},{"location":"python/","title":"Python","text":""},{"location":"security/","title":"Security","text":"<ul> <li>Password Pusher</li> </ul>"},{"location":"terraform/","title":"Terraform","text":""},{"location":"terraform/#terrform-info","title":"Terrform info","text":"<p>References: YouTube / Travis Roberts / Getting Started with Terraform</p> <ul> <li>Use the resources instead of variables to set a dependency on the creation of the resource.</li> <li>Terraforms treats all the divided .tf files as the same file.</li> </ul>"},{"location":"terraform/#locals","title":"Locals","text":"<ul> <li>To assign a name to an expression.</li> <li>Update the local to modify all instance of the expression.</li> <li>Helps with repeating values.</li> <li>Overuse can make code difficult to read.</li> </ul>"},{"location":"terraform/#modules","title":"Modules","text":"<ul> <li>Reusable code.</li> <li>Collection of resources.</li> <li>Accepts inputs, produces outputs.</li> <li>Modules are not a single instance of a resource.</li> <li>Modules is a collection of resources.</li> </ul> <p>Example: GitHub / ModuleExample</p>"},{"location":"terraform/#count-vs-for_each","title":"Count vs For_each","text":"<p>Count Use count if the instances of the resources are almost identical. Using the index to identify the different instances.</p> <p>For_each Multiple versions of similar versions. Uses areguments where the value is mapped to a set of strings. Map is a key value pair.</p> <p>Example: GitHub / VNet with Azure Bastion</p>"},{"location":"terraform/#import-vs-data-source","title":"Import vs Data Source","text":""},{"location":"terraform/#import","title":"Import","text":"<ul> <li>Imports infraestructure into Terraform management.</li> <li>Added to Terraform state and managed by Terraform going forward.</li> </ul>"},{"location":"terraform/#data-source","title":"Data Source**","text":"<ul> <li>Allows Terraform to define and use existing infraestructure.</li> <li>Not managed by Terraform.</li> <li>Data refreshed during Terraform Plan.</li> </ul>"},{"location":"terraform/#features-block","title":"Features Block","text":"<p>The Features Block</p>"},{"location":"terraform/#dynamic-blocks","title":"Dynamic Blocks","text":"<p>Use for reosurce that have repetable nested blocks in their arguments. For example, servers can hhave multiple disks or NICs.</p> <p>A for_each loop is used to create multiple similar instances of an object such as a resource. A Dynamic Block uses a for_each loop to create multiple copies of a sub-resource nested inside a resource.</p> <p>Example: GitHub / Dynamic Network Security Group Example</p>"},{"location":"terraform/#override","title":"Override","text":"<p>Avoid using. Useful for automation, it changes settings without modifying source files.</p> <p>Override file allows to override values in a Terraform deployment. It consists of a set of configurations that replace the values in existing .tf files.</p> <p>After all the .tf files are processed by Terraform, the override files are merged into the configuration. The merge replaces the values supplied by the configuration files.</p> <p>The name convention is important. The files are processed or merged in lexicographical order (alphabetic order). Override File Names:</p> <ul> <li>override.tf, override.tf.json</li> <li>test_override.tf, test_override.tf.json</li> </ul>"},{"location":"terraform/#terrform-practice","title":"Terrform practice","text":"<p>References:</p> <ul> <li>YouTube/ freeCodeCamp / Learn Terraform with Azure by Building a Dev Environment \u2013 Full Course for Beginners</li> </ul>"},{"location":"terraform/#install-terraform","title":"Install Terraform","text":"<ol> <li>Donwload terraform.exe</li> <li>Move to \"C:\\Program Files\\Terraform\"</li> <li>Edit PATH environment variable</li> <li><code>terraform --version</code></li> </ol>"},{"location":"terraform/#azure-login","title":"Azure login","text":"<p>Azure CLI</p> <pre><code>az login --use-device-code\naz account show\naz account set --subscription &lt;subscription_id&gt;\n\naz group list --query \"[?name=='mtc-resources']\"\naz network vnet subnet list -g rg-mock --vnet-name vnet-mock --query \"[?name=='subnet-mock']\"\n\naz vm image list --all --publisher=\"Canonical\" &gt; images.json\naz vm image list --all --publisher=\"Canonical\" --sku=\"22_04-lts-gen2\"\n</code></pre>"},{"location":"terraform/#azure-storage-account","title":"Azure Storage account","text":"<p>The Storage account name has to be unique.</p> <p>Do not create the Storage Account with Terraform. Consider that the Terraform state file in the Storage Account is not a stateless resource. Meaning it cannot be destroyed and recreat it as needed. There is state date in the Storage Account needed for deployments.</p> <p>The ACCOUNT_KEY is not needed if the deployment is don trough a Pipeline.</p> <p>Code</p> BashPowerShell <pre><code>az storage account create\n</code></pre> <pre><code>$SUBCRIPTION_NAME=''\n$RESOURCE_GROUP_NAME='rg-tfstate'\n$STORAGE_ACCOUNT_NAME=\"tfstate01$(get-random)\"\n$CONTAINER_NAME='tfstate'\n\n# Set subscription to be the current active subscription.\naz account show\naz account set --subscription &lt;subscription_id&gt;\n\n# Create resource group\naz group create --name $RESOURCE_GROUP_NAME --location eastus\n\n# Create storage account\naz storage account create --resource-group $RESOURCE_GROUP_NAME --name $STORAGE_ACCOUNT_NAME --sku Standard_LRS --encryption-services blob\n\n# Create blob container\naz storage container create --name $CONTAINER_NAME --account-name $STORAGE_ACCOUNT_NAME\n\n#Get the storage access key and store it as an environment variable\n$ACCOUNT_KEY=$(az storage account keys list --resource-group $RESOURCE_GROUP_NAME --account-name $STORAGE_ACCOUNT_NAME --query '[0].value' -o tsv) \n$env:ARM_ACCESS_KEY=$ACCOUNT_KEY\n</code></pre> <p>Docs: azurerm</p>"},{"location":"terraform/#terraform-commands","title":"Terraform commands","text":"Terraform commands<pre><code>terraform init\nterraform frmt\nterraform plan\n\nterraform apply -help\nterraform apply\nterraform apply -auto-approve\nterraform apply -replace azurerm_linux_virtual_machine.mtc-vm\nterraform apply -refresh-only\n\nterraform state list\nterraform state show azurerm_resource_group.mtc-rg\nterraform state show azurerm_public_ip.mtc-nic\n\nterraform output\nterraform output public_ip_address\n\nterraform refresh\n\nterraform plan -destroy\nterraform apply -destroy\nterraform destroy\n</code></pre>"},{"location":"terraform/#terraform-code","title":"Terraform code","text":"<p>State file and its backup, do not modify unless is strictly necessary. More info: Terraform / State</p> <p>In mtc-test-rule.source_address_prefix, should be your public IP to connect to the Azure resources from local.</p>"},{"location":"terraform/#access-the-vm","title":"Access the VM","text":"<p>Create SSH key to access the VM:</p> <pre><code>ssh-keygen -t rsa\n&gt; C:\\Users\\dumitrux/.ssh/privatekey\n\nls ~/.ssh\n</code></pre> <p>SSH into the VM</p> <pre><code>terraform state show azurerm_public_ip.mtc-vm\n</code></pre> <pre><code>ssh -i ~/.ssh/privatekey adminuser@&lt;vm_ip&gt;\nlsb_release -a\n</code></pre>"},{"location":"terraform/#custom-data","title":"Custom data","text":"<p>This will delete and create the VM</p> <pre><code>ssh -i ~/.ssh/privatekey adminuser@&lt;vm_ip&gt;\ndocker --version\n</code></pre>"},{"location":"terraform/#install-remote-ssh-vsc-extension-to-access-the-remote-vm","title":"Install remote SSH VSC extension to access the remote VM","text":"<ol> <li>Install VSC extension \"Remote - SSH\"</li> <li>Open Command Palette (Ctrl+Shift+P)</li> <li>Type \"Remote-ssh: Add New SSH Host...\"</li> <li>Type \"ssh adminuser@\" <li>Chose \"~/.ssh/config\" directory</li> <li>Open config file</li> <li>Create \"windows-ssh-script.tpl\" and \"linux-ssh-script.tpl\"</li> <li>Add the \"provisioner\" attribute in the \"azurerm_linux_virtual_machine\"</li> <li>Redeploy all <code>terraform apply -replace azurerm_linux_virtual_machine.mtc-vm</code></li> <li>Type \"Remote-ssh: Connect to Host...\" on the Command Palette</li> <li>Select the identifier of the remote machine</li> <li>Select Linux</li> <li>Click \"Continue\" on the provided fingerprint</li> <li>Wait for docker to be installed and check with <code>docker -version</code></li>"},{"location":"terraform/#data-sources","title":"Data sources","text":"<ol> <li>Add <code>data \"azurerm_public_ip\" \"mtc-ip-data\"</code> in the code</li> <li>Run <code>terraform apply -refresh-only</code></li> <li>The data will be at the top of the state file</li> <li>Check the data with <code>terraform state list</code></li> <li>Check the value of the data with <code>terraform state show data.azurerm_public_ip.mtc-ip-data</code></li> </ol>"},{"location":"terraform/#outputs","title":"Outputs","text":"<ol> <li>Add <code>output \"public_ip_adrress\"</code> in the code</li> <li>Check value with <code>terraform state show data.azurerm_public_ip.mtc-ip-data</code></li> <li>Run <code>terraform apply -refresh-only</code></li> <li>Run <code>terraform output</code> or <code>terraform output public_ip_address</code></li> </ol>"},{"location":"terraform/#variables","title":"Variables","text":"<ol> <li>Add <code>${var.host_os}</code> in the templatefile of the VM provisioner</li> <li>Create <code>variables.tf</code> with the <code>host_os</code>variable and plan the deployment</li> <li>Add the attribute <code>default</code> to the <code>variables.tf</code> file</li> <li>Run <code>terraform console</code> and type <code>var.host_os</code></li> <li>Comment the <code>default</code> attribute</li> <li>Create <code>terraform.tfvars</code></li> <li>Run <code>terraform console</code> and type <code>var.host_os</code></li> <li>Run <code>terraform console -var=\"host_os=linux\"</code> and type <code>var.host_os</code></li> <li>Create <code>osx.tfvars</code></li> <li>Run <code>terraform console -var-file=\"osx.tfvars\"</code> and type <code>var.host_os</code></li> </ol>"},{"location":"terraform/#conditionals","title":"Conditionals","text":"<ol> <li>Syntax <code>condition ? true_val : false_val</code></li> <li>Add the conditional in the VM provisioner</li> <li>Run <code>terraform apply -auto-approve</code></li> </ol>"},{"location":"vim/","title":"Vim","text":""},{"location":"vscode/","title":"Visual Studio Code","text":""},{"location":"vscode/#extensions","title":"Extensions","text":""},{"location":"vscode/#visualization","title":"Visualization","text":"<ul> <li>GitHub Theme (github.github-vscode-theme)</li> <li>vscode-icons (vscode-icons-team.vscode-icons)</li> <li>Git History (donjayamanne.githistory)</li> </ul>"},{"location":"vscode/#programming-and-scripting-languages","title":"Programming and scripting languages","text":"<ul> <li>Python (ms-python.python)</li> <li>Go (golang.go)</li> <li>YAML (redhat.vscode-yaml)</li> <li>PowerShell (ms-vscode.powershell)</li> </ul>"},{"location":"vscode/#copilot","title":"Copilot","text":"<ul> <li>GitHub Copilot (github.copilot)</li> <li>GitHub Copilot Chat (github.copilot-chat)</li> </ul>"},{"location":"vscode/#containerization","title":"Containerization","text":"<ul> <li>Dev Containers (ms-vscode-remote.remote-containers)</li> <li>Docker (ms-azuretools.vscode-docker)</li> <li>GitHub Codespaces (github.codespaces)</li> <li>Kubernetes (ms-kubernetes-tools.vscode-kubernetes-tools)</li> </ul>"},{"location":"vscode/#documentation","title":"Documentation","text":"<ul> <li>Markdown All in One (yzhang.markdown-all-in-one)</li> <li>markdownlint (davidanson.vscode-markdownlint)</li> </ul>"},{"location":"vscode/#iac","title":"IaC","text":"<ul> <li>HashiCorp Terraform (hashicorp.terraform)</li> <li>Azure CLI Tools (ms-vscode.azurecli)</li> <li>Azure Pipelines (ms-azure-devops.azure-pipelines)</li> <li>Azure Terraform (ms-azuretools.vscode-azureterraform)</li> </ul>"},{"location":"vscode/#miscellany","title":"Miscellany","text":"<ul> <li>WSL (ms-vscode-remote.remote-wsl)</li> <li>Remote - SSH (ms-vscode-remote.remote-ssh)</li> <li>REST Client (humao.rest-client)</li> </ul>"},{"location":"vscode/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"<p>Ctrl+Shift+P</p> <p>The most important key combination to know, since it brings up the Command Palette. From here, you have access to all of the functionality of VS Code, including keyboard shortcuts for the most common operations. The Command Palette provides access to many commands.</p> <p>Ctrl+P</p> <p>Quickly open files.</p>"},{"location":"vscode/#references","title":"References","text":"<ul> <li>Visual Studio Code Tips and Tricks</li> </ul>"},{"location":"cicd/github-actions/","title":"GitHub Actions","text":""},{"location":"cicd/github-actions/#registration","title":"Registration","text":"<ul> <li>GitHub Partner Certifications</li> <li>GitHub Partner Certifications - Candidate Handbook</li> <li>GitHub Partner Certifications - FAQ</li> </ul>"},{"location":"cicd/github-actions/#introduction","title":"Introduction","text":"<ul> <li>Quickstart for GitHub Actions</li> </ul>"},{"location":"cicd/github-actions/#general","title":"General","text":"<ul> <li>MSFT Learn GitHub Actions Collection</li> <li>MSFT Learn Path: Automate your workflow with GitHub Actions</li> <li>GitHub Actions documentation</li> </ul>"},{"location":"cicd/github-actions/#most-relevant-sections","title":"Most relevant sections","text":""},{"location":"cicd/github-actions/#learn-github-actions","title":"Learn GitHub Actions","text":"<ul> <li>Understanding GitHub Actions</li> <li>Essential features of GitHub Actions</li> <li>Contexts</li> <li>Variables</li> <li>Usage limits, billing, and administration</li> </ul>"},{"location":"cicd/github-actions/#using-workflows","title":"Using Workflows","text":"<ul> <li>Disabling and enabling a workflow</li> <li>Events that trigger workflows</li> <li>Workflow syntax for GitHub Actions</li> <li>Caching dependencies to speed up workflows</li> <li>Storing workflow data as artifacts</li> <li>Sharing workflows, secrets, and runners with your organization</li> </ul>"},{"location":"cicd/github-actions/#build-and-test","title":"Build and test","text":"<ul> <li>About continuous integration</li> </ul>"},{"location":"cicd/github-actions/#deployment-target-different-environments","title":"Deployment - Target different environments","text":"<ul> <li>Using environments for deployment</li> </ul>"},{"location":"cicd/github-actions/#monitor-troubleshoot","title":"Monitor &amp; troubleshoot","text":"<ul> <li>Adding a workflow status badge</li> <li>Using workflow run logs</li> <li>Enabling debug logging</li> </ul>"},{"location":"cicd/github-actions/#github-and-self-hosted-runners","title":"GitHub and Self-hosted runners","text":"<ul> <li>About GitHub-hosted runners</li> <li>About self-hosted runners</li> </ul>"},{"location":"cicd/github-actions/#creating-actions","title":"Creating actions","text":"<ul> <li>Metadata syntax for GitHub Actions</li> </ul>"},{"location":"cicd/github-actions/#github-actions-api","title":"GitHub Actions API","text":"<ul> <li>GitHub REST API</li> <li>GitHub REST API - Actions artifacts</li> <li>GitHub REST API - Workflow runs</li> </ul>"},{"location":"cicd/github-actions/#dependencies","title":"Dependencies","text":"<ul> <li>Webhook events and payloads</li> <li>MSFT Learn - Intro to Docker containers</li> <li>GitHub API - Octokit</li> </ul>"},{"location":"cicd/github-actions/#common-cicd-actions","title":"Common CI/CD Actions","text":"<ul> <li>GitHub Marketplace</li> <li>GitHub Actions starter-workflow</li> <li>actions/upload-artifact</li> <li>actions/download-artifact</li> <li>actions/github-script</li> <li>azure/webapps-deploy@v2</li> <li>azure/login@v1</li> <li>azure/docker-login@v1</li> <li>pullreminders/label-when-approved-action</li> </ul>"},{"location":"cicd/github-actions/#samples","title":"Samples","text":"<ul> <li>midudev/pokedex-for-ci</li> </ul>"},{"location":"cicd/github-actions/#examples","title":"Examples","text":"github-actions-demo.yml<pre><code>name: GitHub Actions Demo\n\nrun-name: ${{ github.actor }} is testing out GitHub Actions \ud83d\ude80\non:\n  workflow_dispatch:\n  push:\n    branches: [main]\n\njobs:\n  Explore-GitHub-Actions:\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"\ud83c\udf89 The job was automatically triggered by a ${{ github.event_name }} event.\"\n      - run: echo \"\ud83d\udc27 This job is now running on a ${{ runner.os }} server hosted by GitHub!\"\n      - run: echo \"\ud83d\udd0e The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}.\"\n      - name: Check out repository code\n        uses: actions/checkout@v3\n      - run: echo \"\ud83d\udca1 The ${{ github.repository }} repository has been cloned to the runner.\"\n      - run: echo \"\ud83d\udda5\ufe0f The workflow is now ready to test your code on the runner.\"\n      - name: List files in the repository\n        run: |\n          ls ${{ github.workspace }}\n      - run: echo \"\ud83c\udf4f This job's status is ${{ job.status }}.\"\n</code></pre>"},{"location":"containers/docker/","title":"Docker","text":"<p>Docs Docker / Overview of the get started guide</p>"},{"location":"containers/docker/#1-run-docker-tutorial-image","title":"1 - Run Docker tutorial image","text":""},{"location":"containers/docker/#clone","title":"Clone","text":"<pre><code>docker run --name repo alpine/git clone https://github.com/docker/getting-started.git\ndocker cp repo:/git/getting-started/ .\n</code></pre>"},{"location":"containers/docker/#build","title":"Build","text":"<pre><code>cd getting-started\ndocker build -t docker101tutorial .\n</code></pre>"},{"location":"containers/docker/#run","title":"Run","text":"<pre><code>docker run -d -p 80:80 --name docker-tutorial docker101tutorial\n</code></pre>"},{"location":"containers/docker/#2-getting-started-app","title":"2 - Getting started app","text":""},{"location":"containers/docker/#getting-app-obtain-image","title":"Getting App / Obtain Image","text":"<p>Download the ZIP file with the app.</p>"},{"location":"containers/docker/#build-from-dockerfile","title":"Build from Dockerfile","text":"<pre><code>docker build -t getting-started .\n</code></pre>"},{"location":"containers/docker/#run-container","title":"Run Container","text":"<pre><code>docker run -dp 3000:3000 getting-started\n</code></pre> <ul> <li>-d - run the container in detached mode (in the background)</li> <li>-p 80:80 - map port 80 of the host to port 80 in the container</li> <li>docker/getting-started - the image to use</li> </ul> <pre><code>docker ps -a\ndocker stop &lt;the-container-id&gt;\ndocker rm &lt;the-container-id&gt;\n\n# Stop and remove\ndocker rm -f &lt;the-container-id&gt;\n</code></pre>"},{"location":"containers/docker/#3-persistence-with-named-volumes","title":"3 - Persistence with Named Volumes","text":"<p>Named Volumes when you do not have to worry about where the data is stored.</p>"},{"location":"containers/docker/#persistance-example","title":"Persistance example","text":"<pre><code>docker run -d ubuntu bash -c \"shuf -i 1-10000 -n 1 -o /data.txt &amp;&amp; tail -f /dev/null\"\ndocker exec &lt;container-id&gt; cat /data.txt\ndocker run -it ubuntu ls /\n</code></pre>"},{"location":"containers/docker/#persistance-in-getting-started-app","title":"Persistance in getting-started app","text":"<pre><code>docker volume create todo-db\ndocker run -dp 3000:3000 -v todo-db:/etc/todos getting-started\n</code></pre>"},{"location":"containers/docker/#4-persistence-with-bind-mounts","title":"4 - Persistence with Bind Mounts","text":"<p>With bind mounts, we control the exact mountpoint on the host. Often used to provide additional data into containers.</p> <pre><code>docker run -dp 3000:3000 `\n    -w /app -v \"$(pwd):/app\" `\n    node:12-alpine `\n    sh -c \"yarn install &amp;&amp; yarn run dev\"\n</code></pre> <ul> <li>-dp 3000:3000 - same as before. Run in detached (background) mode and create a port mapping</li> <li>-w /app - sets the container's present working directory where the command will run from</li> <li>-v \"$(pwd):/app\" - bind mount (link) the host's present getting-started/app directory to the container's /app directory (Docker requires absolute paths).</li> <li>node:12-alpine - the image to use. Note that this is the base image for our app from the Dockerfile</li> <li>sh -c \"yarn install &amp;&amp; yarn run dev\" - the command. We're starting a shell using sh (alpine doesn't have bash) and running yarn install to install all dependencies and then running yarn run dev.</li> </ul> <p>Check logs with:</p> <pre><code>docker logs -f &lt;container-id&gt;\n</code></pre>"},{"location":"containers/docker/#5-multi-container-apps","title":"5 - Multi-Container Apps","text":""},{"location":"containers/docker/#starting-mysql","title":"Starting MySQL","text":"<pre><code>docker network create todo-app\n</code></pre> <pre><code>docker run -d `\n    --network todo-app --network-alias mysql `\n    -v todo-mysql-data:/var/lib/mysql `\n    -e MYSQL_ROOT_PASSWORD=secret `\n    -e MYSQL_DATABASE=todos `\n    mysql:5.7\n</code></pre> <p>Docker recognizes we want to use a named volume and creates one automatically for us, so it create the volume named todo-mysql-data and mounting it at /var/lib/mysql, which is where MySQL stores its data.</p> <pre><code>docker exec -it &lt;mysql-container-id&gt; mysql -p\n&gt; secret\nmysql&gt; SHOW DATABASES;\n</code></pre>"},{"location":"containers/docker/#connecting-to-mysql","title":"Connecting to MySQL","text":"<p>We're going to make use of the nicolaka/netshoot container, which ships with a lot of tools that are useful for troubleshooting or debugging networking issues.</p> <pre><code>docker run -it --network todo-app nicolaka/netshoot\n&gt; dig mysql\n</code></pre> <p>172.18.0.2</p>"},{"location":"containers/docker/#running-our-app-with-mysql","title":"Running our App with MySQL","text":"<p>The todo app supports the setting of a few environment variables to specify MySQL connection settings. They are:</p> <ul> <li>MYSQL_HOST - the hostname for the running MySQL server</li> <li>MYSQL_USER - the username to use for the connection</li> <li>MYSQL_PASSWORD - the password to use for the connection</li> <li>MYSQL_DB - the database to use once connected</li> </ul> <p>Only use environment variables in development not in production, for security reasons use files instead \"*_FILE\".</p> <pre><code>docker run -dp 3000:3000 `\n  -w /app -v \"$(pwd):/app\" `\n  --network todo-app `\n  -e MYSQL_HOST=mysql `\n  -e MYSQL_USER=root `\n  -e MYSQL_PASSWORD=secret `\n  -e MYSQL_DB=todos `\n  node:12-alpine `\n  sh -c \"yarn install &amp;&amp; yarn run dev\"\n</code></pre> <p>Connect to the mysql database and prove that the items are being written to the database.</p> <pre><code>docker exec -it ddc4af07d4a6 mysql -p todos\n&gt; secret\nmysql&gt; select * from todo_items;\n</code></pre>"},{"location":"containers/docker/#6-using-docker-compose","title":"6 - Using Docker Compose","text":"<p>At the root of the app project, create a file named \"docker-compose.yml\".</p>"},{"location":"containers/docker/#defining-the-app-service","title":"Defining the App Service","text":"<p>From:</p> <pre><code>docker run -dp 3000:3000 `\n  -w /app -v \"$(pwd):/app\" `\n  --network todo-app `\n  -e MYSQL_HOST=mysql `\n  -e MYSQL_USER=root `\n  -e MYSQL_PASSWORD=secret `\n  -e MYSQL_DB=todos `\n  node:12-alpine `\n  sh -c \"yarn install &amp;&amp; yarn run dev\"\n</code></pre> <p>To:</p> <pre><code>version: \"3.8\"\n\nservices:\n  app:\n    image: node:12-alpine\n    command: sh -c \"yarn install &amp;&amp; yarn run dev\"\n    ports:\n      - 3000:3000\n    working_dir: /app\n    volumes:\n      - ./:/app\n    environment:\n      MYSQL_HOST: mysql\n      MYSQL_USER: root\n      MYSQL_PASSWORD: secret\n      MYSQL_DB: todos\n</code></pre> <p>Compose has short syntax and long syntax. For example, in ports and volumes. Here we can also specify relative paths instead of abosolute.</p>"},{"location":"containers/docker/#defining-the-mysql-service","title":"Defining the MySQL Service","text":"<p>From:</p> <pre><code>docker run -d `\n  --network todo-app --network-alias mysql `\n  -v todo-mysql-data:/var/lib/mysql `\n  -e MYSQL_ROOT_PASSWORD=secret `\n  -e MYSQL_DATABASE=todos `\n  mysql:5.7\n</code></pre> <p>To:</p> <pre><code>version: \"3.8\"\n\nservices:\n  app:\n    # The app service definition\n  mysql:\n    image: mysql:5.7\n    volumes:\n      - todo-mysql-data:/var/lib/mysql\n    environment: \n      MYSQL_ROOT_PASSWORD: secret\n      MYSQL_DATABASE: todos\n\nvolumes:\n  todo-mysql-data:\n</code></pre> <p>It is needed to define the volume mapping. When we ran the container with docker run, the named volume was created automatically, but not with Compose.</p>"},{"location":"containers/docker/#result-of-docker-composeyml","title":"Result of \"docker-compose.yml\"","text":"<pre><code>version: \"3.8\"\n\nservices:\n  app:\n    image: node:12-alpine\n    command: sh -c \"yarn install &amp;&amp; yarn run dev\"\n    ports:\n      - 3000:3000\n    working_dir: /app\n    volumes:\n      - ./:/app\n    environment:\n      MYSQL_HOST: mysql\n      MYSQL_USER: root\n      MYSQL_PASSWORD: secret\n      MYSQL_DB: todos\n\n  mysql:\n    image: mysql:5.7\n    volumes:\n      - todo-mysql-data:/var/lib/mysql\n    environment: \n      MYSQL_ROOT_PASSWORD: secret\n      MYSQL_DATABASE: todos\n\nvolumes:\n  todo-mysql-data:\n</code></pre>"},{"location":"containers/docker/#running-our-application-stack","title":"Running our Application Stack","text":"<pre><code>docker-compose up -d\ndocker-compose logs -f\ndocker-compose logs -f app\n</code></pre> <p>Docker Compose automatically creates a network specifically for the application stack.</p> <p>When the app is starting up, it actually sits and waits for MySQL to be up and ready before trying to connect to it. Docker doesn't have any built-in support to wait for another container to be fully up, running, and ready before starting another container.</p>"},{"location":"containers/docker/#tearing-it-all-down","title":"Tearing it All Down","text":"<pre><code>docker-compose down\n</code></pre> <p>By default, named volumes in your compose file are NOT removed when running docker-compose down. If you want to remove the volumes, you will need to add the --volumes flag.</p>"},{"location":"containers/docker/#7-image-building-best-practices","title":"7- Image Building Best Practices","text":""},{"location":"containers/docker/#security-scanning","title":"Security Scanning","text":"<p>When you have built an image, it is good practice to scan it for security vulnerabilities.</p> <pre><code>docker scan getting-started\n</code></pre>"},{"location":"containers/docker/#image-layering","title":"Image Layering","text":"<p>You can see the command that was used to create each layer within an image</p> <pre><code>docker image history getting-started\ndocker image history --no-trunc getting-started\n</code></pre>"},{"location":"containers/docker/#layer-caching","title":"Layer Caching","text":"<p>Avoid yarn dependencies had to be reinstalled to decrease build times for your container images.</p> <ol> <li>Update the Dockerfile to copy in the package.json first, install dependencies, and then copy everything else in.</li> </ol> <pre><code>FROM node:12-alpine\nWORKDIR /app\nCOPY package.json yarn.lock ./\nRUN yarn install --production\nCOPY . .\nCMD [\"node\", \"src/index.js\"]\n</code></pre> <ol> <li>Create a file named .dockerignore in the same folder as the Dockerfile with the following contents.</li> </ol> <pre><code>node_modules\n</code></pre> <ol> <li>Build a new image using docker build.</li> </ol> <pre><code>docker build -t getting-started .\n</code></pre>"},{"location":"containers/docker/#multi-stage-builds","title":"Multi-Stage Builds","text":"<p>When building React applications, we need a Node environment to compile the JS code, SASS, and more into static HTML, JS, and CSS. If we aren't doing server-side rendering, we don't even need a Node environment for our production build. Why not ship the static resources in a static nginx container?</p> <pre><code>FROM node:12 AS build\nWORKDIR /app\nCOPY package* yarn.lock ./\nRUN yarn install\nCOPY public ./public\nCOPY src ./src\nRUN yarn run build\n\nFROM nginx:alpine\nCOPY --from=build /app/build /usr/share/nginx/html\n</code></pre> <p>Here, we are using a node:12 image to perform the build (maximizing layer caching) and then copying the output into an nginx container.</p>"},{"location":"containers/kubernetes/","title":"Kubernetes","text":""},{"location":"containers/kubernetes/#usefult-resources","title":"Usefult resources","text":"<ul> <li>KodeKloud | CKA Certification Course \u2013 Certified Kubernetes Administrator</li> <li>Network Policy Editor for Kubernetes</li> <li>Kubernetes instance calculator</li> </ul>"},{"location":"containers/kubernetes/#example","title":"Example","text":"<p>Based on the example</p> <ul> <li>freeCodeCamp - Kubernetes Course - Full Beginners Tutorial</li> <li>GitHub repository for the \"Kubernetes for Beginners\"</li> </ul>"},{"location":"containers/kubernetes/#1-creating-kubernetes-cluster-using-minikube","title":"1 - Creating Kubernetes cluster using Minikube","text":""},{"location":"containers/kubernetes/#create-cluster","title":"Create cluster","text":"<pre><code>minikube status\nminikube start --driver=hyperv\nminikube status\n</code></pre>"},{"location":"containers/kubernetes/#connect-to-cluster","title":"Connect to cluster","text":"<p>Connect to local server with the standard protocol SSH.</p> <pre><code>minikube ip\nssh docker@&lt;k8s-cluster-IP&gt;\n&gt; tcuser\n\ndocker ps\n</code></pre> <p>Minikube also provides command to SSH into local minikube node. If you set the driver to docker you should use this one because normal SSH will not work.</p> <pre><code>minikube ssh\n</code></pre>"},{"location":"containers/kubernetes/#exploring-with-kubectl","title":"Exploring with Kubectl","text":"<p>Can only be exxecuted inside the cluster with:</p> <pre><code>minikube kubectl\n</code></pre> <p>But it is recommended to use the default kubctl outside the cluster. The connection is automatically created once Minikube is started.</p> <pre><code>kubectl cluster-info\nkubectl get nodes\nkubectl get pods\nkubectl get namespaces\n\nkubectl get pods --namespace=kube-system\n</code></pre>"},{"location":"containers/kubernetes/#2-creating-just-single-pod","title":"2 - Creating just single Pod","text":"<p>Name of the Pod can be whatever and the image is from the Docker Hub.</p> <pre><code>kubectl run nginx --image=nginx\nkubectl get pod\nkubectl describe pod nginx\n</code></pre>"},{"location":"containers/kubernetes/#exploring-pod","title":"Exploring Pod","text":"<p>Inside the cluster:</p> <pre><code>docker ps | grep nginx\ndocker exec -it &lt;container-id&gt; sh\n&gt; hostname\n&gt; hostname -i\n&gt; curl &lt;container-ip&gt;\n</code></pre> <p>Outside the cluster:</p> <pre><code>kubectl get pods -o wide\ncurl 172.17.0.3\n</code></pre> <p>Several container in the same Pod share the same IP. IP address is internal from the Pod and it is not possible to connect from outside.</p> <pre><code>kubectl delete pod nginx\nkubectl get pods\n</code></pre>"},{"location":"containers/kubernetes/#3-creating-and-exploring-deployment","title":"3 - Creating and exploring Deployment","text":"<p>Deployments are responsible of the creation of the Pods. All pods inside the deployment will be exactly the same.</p> <pre><code>kubectl create deployment nginx-deployment --image=nginx\nkubectl get deployments\nkubectl get pods\nkubectl describe deployment nginx-deployment\n</code></pre>"},{"location":"containers/kubernetes/#scale-deployment","title":"Scale deployment","text":"<pre><code>kubectl scale deployment nginx-deployment --replicas=5\nkubectl get pods\nkubectl get pods -o wide\n</code></pre> <pre><code>kubectl scale deployment nginx-deployment --replicas=3\nkubectl get pods -o wide\n</code></pre>"},{"location":"containers/kubernetes/#4-service","title":"4 - Service","text":""},{"location":"containers/kubernetes/#creating-and-exploring-clusterip-service","title":"Creating and exploring ClusterIP Service","text":"<p>IP address assigned to deployment and it only can be used inside the cluster.</p> <pre><code>kubectl get deploy\nkubectl expose deployment nginx-deployment --port=8080 --target-port=80\nkubectl get services\nkubectl get svc\nkubectl describe service nginx-deployment\n</code></pre>"},{"location":"containers/kubernetes/#deleting-deployment-and-service","title":"Deleting Deployment and Service","text":"<pre><code>kubectl delete deployment nginx-deployment\nkubectl delete service nginx-deployment\n</code></pre>"},{"location":"containers/kubernetes/#5-node-application-example","title":"5 - Node application example","text":""},{"location":"containers/kubernetes/#creating-node-web-application","title":"Creating Node web application","text":"<p>Set up node app</p> <pre><code>New-Item -Path . -Name \"k8s-web-hello\" -ItemType \"directory\"\nnpm init -y\nnpm install express\nRemove-Item -Recurse -Force node_modules\nNew-Item -Path . -Name \"index.mjs\" -ItemType \"file\"\nGet-ChildItem\n</code></pre>"},{"location":"containers/kubernetes/#dockerizing-node-application-and-pushing-custom-image-to-the-docker-hub","title":"Dockerizing Node application and pushing custom image to the Docker Hub","text":"<pre><code>New-Item -Path . -Name \"Dockerfile\" -ItemType \"file\"\ndocker build . -t mitu7/k8s-web-hello\ndocker images | Select-String -Pattern k8s-web\ndocker login\n&gt; mitu7\ndocker push mitu7/k8s-web-hello\n</code></pre>"},{"location":"containers/kubernetes/#creating-deployment-based-on-the-custom-docker-image","title":"Creating deployment based on the custom Docker image","text":"<pre><code>kubectl get deploy\nkubectl get svc\nkubectl create deployment k8s-web-hello --image=mitu7/k8s-web-hello\nkubectl get pods\nkubectl expose deployment k8s-web-hello --port=3000\n</code></pre>"},{"location":"containers/kubernetes/#scaling-custom-image-deployment","title":"Scaling custom image deployment","text":"<pre><code>kubectl scale deployment k8s-web-hello --replicas=4\nkubectl get pods\nkubectl get pods -o wide\n\n# Inside the cluster\ncurl &lt;service-ClusterIP&gt;; echo\n</code></pre>"},{"location":"containers/kubernetes/#creating-nodeport-service","title":"Creating NodePort Service","text":"<p>This service IP is avaiable externally</p> <pre><code>kubectl delete svc k8s-web-hello\nkubectl get svc\nkubectl expose deployment k8s-web-hello --type=NodePort --port=3000\nkubectl get svc\ncurl &lt;Minikube-IP&gt;:&lt;Target port&gt;\nminikube service k8s-web-hello\nminikube service k8s-web-hello --url\n</code></pre>"},{"location":"containers/kubernetes/#creating-loadbalancer-service","title":"Creating LoadBalancer Service","text":"<p>When creating the LoadBalancer service type in a Cloud environment, the External-IP will be assigned automatically here it is in state <code>&lt;pending&gt;</code>.</p> <pre><code>kubectl delete svc k8s-web-hello\nkubectl expose deployment k8s-web-hello --type=LoadBalancer --port=3000\nminikube service k8s-web-hello\n</code></pre>"},{"location":"containers/kubernetes/#rolling-update-of-the-deployment","title":"Rolling update of the deployment","text":"<p>The StrategyType is RollingUpdate, helps tou roll out new version of application to the production environment without any interruption. This strategy means that new Pods will be created with new image, while previous Pods are still running, so Pods will be replace one by one.</p> <p>Generate new image</p> <pre><code>kubectl describe deployment k8s-web-hello\ndocker build . -t mitu7/k8s-web-hello:2.0.1\ndocker push mitu7/k8s-web-hello:2.0.1\n</code></pre> <p>Set new image for the deployment If you quickly execute the second command here, you will see how the Pods are being updated</p> <pre><code>kubectl set image deployment k8s-web-hello k8s-web-hello=mitu7/k8s-web-hello:2.0.1\nkubectl rollout status deploy k8s-web-hello\n</code></pre>"},{"location":"containers/kubernetes/#what-happens-when-one-of-the-pods-is-deleted","title":"What happens when one of the pods is deleted","text":"<p>If you delete a Pod a new one will be created automatically, because we told Kubernetes that the desire number of Pods</p> <pre><code>kubectl delete pod &lt;Pod-name&gt;\nkubectl get pods\n</code></pre>"},{"location":"containers/kubernetes/#kubernetes-dashboard","title":"Kubernetes Dashboard","text":"<p>This is easy in Minikube, but in the Cloud it is needed to secure the net access</p> <pre><code>minikube dashboard\n</code></pre>"},{"location":"containers/kubernetes/#6-node-application-example-with-yaml","title":"6 - Node application example with YAML","text":""},{"location":"containers/kubernetes/#creating-yaml-deployment-specification-file","title":"Creating YAML deployment specification file","text":"<p>Instead of using imperative approach we will use declarative approach, which is more used.</p> <p>Clean up. Note that when deleting all the Kubernetes service is recreated again.</p> <pre><code>kubectl delete all --all\nkubectl get pods\nkubectl get svc \nkubectl get deployments\n</code></pre> <p>It is need to create a YAML file for deployment and another for service. If you have Kubernetes VSC extension and type \"Deployment\" the configuration basic file will be automatically created.</p> <pre><code>New-Item -Path . -Name \"deployment.yaml\" -ItemType \"file\"\n</code></pre> <p>deployment.yaml</p>"},{"location":"containers/kubernetes/#how-to-use-kubernetes-documentation","title":"How to use Kubernetes documentation","text":"<p>Kubernetes API</p>"},{"location":"containers/kubernetes/#applying-yaml-deployment-file","title":"Applying YAML deployment file","text":"<pre><code>kubectl apply -f deployment.yaml\nkubectl get deploy\n</code></pre> <p>Add \"replicas\" entry in deployment.yaml file</p> <pre><code>kubectl apply -f deployment.yaml\n</code></pre>"},{"location":"containers/kubernetes/#creating-yaml-service-specification-file","title":"Creating YAML service specification file","text":"<p>As in the deployment.yaml file, if you have hte extension just type \"Service\" and the basic configuration will be created.</p> <pre><code>New-Item -Path . -Name \"service.yaml\" -ItemType \"file\"\nkubectl apply -f service.yaml\nkubectl get svc\nminikube service k8s-web-hello\n</code></pre> <p>service.yaml</p>"},{"location":"containers/kubernetes/#delete-all-created-by-the-yaml-files","title":"Delete all created by the YAML files","text":"<pre><code>kubectl delete -f deployment.yaml -f service.yaml\nkubectl get deploy\nkubectl get svc\n</code></pre>"},{"location":"containers/kubernetes/#7-ngninx-application-with-two-endpoints","title":"7 - Ngninx application with two endpoints","text":""},{"location":"containers/kubernetes/#creating-another-web-app-with-two-endpoints","title":"Creating another web app with two endpoints","text":"<p>Make a copy of the \"k8s-web-hello\" folder and call it \"k8s-web-to-nginx\"</p>"},{"location":"containers/kubernetes/#building-custom-docker-image-for-the-second-web-app","title":"Building custom Docker image for the second web app","text":"<pre><code>npm install node-fetch\nRemove-Item -Recurse -Force node_modules\ndocker build . -t mitu7/k8s-web-to-nginx\ndocker push mitu7/k8s-web-to-nginx\n</code></pre>"},{"location":"containers/kubernetes/#creating-yaml-specification-for-the-second-web-app","title":"Creating YAML specification for the second web app","text":"<p>Create the file \"k8s-web-to-nginx.yaml\" and copy&amp;paste the content of \"service.yaml\", then add \"---\" at the end of the file and copy at the end the content of the \"deployment.yaml\".</p>"},{"location":"containers/kubernetes/#creating-yaml-specification-for-the-nginx-app","title":"Creating YAML specification for the NGINX app","text":"<p>Create a copy of the file \"k8s-web-to-nginx.yaml\" and rename it to \"nginx.yaml\" and edit it to create the nginx deployment and service</p>"},{"location":"containers/kubernetes/#applying-specifications-for-both-apps","title":"Applying specifications for both apps","text":"<pre><code>kubectl apply -f \"k8s-web-to-nginx.yaml\" -f \"nginx.yaml\"\nkubectl get deploy\nkubectl get svc\nkubectl get pods\n</code></pre>"},{"location":"containers/kubernetes/#verifying-connectivity-between-different-deployments","title":"Verifying connectivity between different deployments","text":"<pre><code>minikube service k8s-web-to-nginx\n</code></pre> <p>On the new page add \"/nginx\" at the end</p>"},{"location":"containers/kubernetes/#resolving-service-name-to-ip-address","title":"Resolving Service name to IP address","text":"<pre><code>kubectl get pods\nkubectl exec &lt;Pod-name&gt; -- nslookup nginx\nkubectl get svc\n</code></pre> <p>With this command we tried to resolve \"nginx\" name from inside the container which belongs to that Pod. The IP obtained it came from the nginx service</p> <p>You can also try to retrieve the web page to verify that the connection is established.</p> <pre><code>kubectl exec &lt;Pod-name&gt; -- wget -qO- http://nginx\n</code></pre>"},{"location":"containers/kubernetes/#deleting-both-applications","title":"Deleting both applications","text":"<pre><code>kubectl delete -f \"k8s-web-to-nginx.yaml\" -f \"nginx.yaml\"\n</code></pre>"},{"location":"containers/kubernetes/#8-changing-container-runtime-from-docker-to-cri-o","title":"8 - Changing Container Runtime from Docker to CRI-O","text":"<p>Delete current cluster</p> <pre><code>minikube status\nminikube stop\nminikube delete\n</code></pre> <p>You can use CRI-O or containerd as a container runtime in the K8S cluster. To see if it worked you can connect to the cluster en execute the docker command to see how it fails and then the specific command for the container runtime.</p> <pre><code>minikube start --drive=hyperv --container-runtime=cri-o\n#minikube start --drive=hyperv --container-runtime=containerd\nminikube status\n\nminikube ip\nssh docker@&lt;cluster-IP&gt;\n&gt; tcuser\ndocker ps\nsudo crictl ps\nsudo crictl ps | grep k8s-web-to-nginx\n</code></pre>"},{"location":"containers/kubernetes/#deploying-apps-using-cri-o-container-runtime","title":"Deploying apps using CRI-O container runtime","text":"<pre><code>kubectl apply -f \"k8s-web-to-nginx.yaml\" -f \"nginx.yaml\"\n</code></pre>"},{"location":"containers/kubernetes/#verifying-connectivity-between-deployments","title":"Verifying connectivity between deployments","text":"<pre><code>minikube service k8s-web-to-nginx\n</code></pre> <p>Once the window is open add \"/nginx\" at the end of the URL.</p>"},{"location":"development/R/","title":"R language","text":""},{"location":"development/R/#references","title":"References","text":"<ul> <li>FreeCodeCamp - R Programming Tutorial - Learn the Basics of Statistical Computing</li> <li>R for Data Science</li> </ul>"},{"location":"development/R/#rstudio","title":"RStudio","text":""},{"location":"development/R/#-rstudio-team-admin-training","title":"- RStudio Team Admin Training","text":""},{"location":"development/websites/","title":"Websites","text":"<ul> <li>Web Check</li> <li>Free for Developers</li> </ul>"},{"location":"documentation/diagrams/","title":"Diagrams","text":"<ul> <li>Draw.io</li> <li>Miro</li> <li>Excalidraw</li> <li>Database Relationship Diagrams Design Tool</li> </ul>"},{"location":"documentation/jekyll/","title":"Jekyll","text":""},{"location":"documentation/jekyll/#install","title":"Install","text":"<pre><code>sudo apt install ruby -y\nruby -v\ngem -v\n\n\nsudo apt install gcc -y\ngcc -v\n\nsudo apt install g++ -y\n\ng++ -v\n\n\nsudo apt install make -y\nmake -v\n\nsudo apt install ruby-bundler -y\nbundle -v\n\nsudo apt install jekyll -y\njekyll new --skip-bundle .\nmkdir jekyll\ncd jekyll\nbundle install\nbundle exec jekyll serve\n\nls -l /usr/lib/ruby/\nrm -rf /usr/lib/ruby/vendor_ruby/\n\nbundle install\nbundle exec jekyll serve\n\n\nbundle update sass\nbundle exec jekyll serve\n</code></pre>"},{"location":"documentation/jekyll/#theme","title":"Theme","text":"<ul> <li>jekyll-gitbook</li> <li>Jekyll Themes</li> </ul>"},{"location":"documentation/jekyll/#configuration","title":"Configuration","text":"<ul> <li>Jekyll</li> <li>Bookdown / HTML</li> </ul>"},{"location":"documentation/jekyll/#disqus","title":"Disqus","text":"<ul> <li>Disqus</li> </ul>"},{"location":"documentation/markdown/","title":"Markdown language","text":""},{"location":"documentation/markdown/#-basic-syntax","title":"- Basic Syntax","text":""},{"location":"documentation/mkdocs/","title":"MkDocs","text":"<pre><code>python -m venv venv\nsource venv/bin/activate\npip --version\n\npip install mkdocs-material\n\nmkdocs new .\nmkdocs serve\n</code></pre>"},{"location":"documentation/mkdocs/#plugins","title":"Plugins","text":"<pre><code>pip install mkdocs-minify-plugin\npip install mkdocs-glightbox\n</code></pre>"},{"location":"documentation/mkdocs/#emojis","title":"Emojis","text":"<ul> <li>Icons, Emojis</li> </ul>"},{"location":"documentation/mkdocs/#references","title":"References","text":"<ul> <li>Create Code Documentation With MkDocs Material Theme</li> <li>squidfunk/mkdocs-material</li> </ul>"},{"location":"documentation/mkdocs/#examples","title":"Examples","text":""},{"location":"documentation/mkdocs/#admonitions","title":"Admonitions","text":"<p>Warning</p> <p>All good, no worries.</p> Phasellus posuere in sem ut cursus <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"documentation/mkdocs/#annotations","title":"Annotations","text":"<p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> I'm an annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be expressed in Markdown.</li> </ol>"},{"location":"documentation/mkdocs/#buttons","title":"Buttons","text":"<p>Subscribe to our newsletter Send </p>"},{"location":"documentation/mkdocs/#code-blocks","title":"Code blocks","text":"<pre><code># Code block content\n</code></pre> <pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"documentation/mkdocs/#customization","title":"Customization","text":"<ul> <li>Additional CSS in <code>docs/stylesheets/extra.css</code> to tweak a specific type of string.</li> <li>Additional JavaScript in <code>docs/javascripts/tablesort.js</code> to make data tables sortable.</li> <li>Pygments styles</li> <li>Pygments languages</li> </ul>"},{"location":"documentation/mkdocs/#content-tabs","title":"Content tabs","text":"BashPowerShell <pre><code>echo \"Hello bash 1!\"\n</code></pre> <pre><code>Write-Host \"Hello PowerShell 1!\"\n</code></pre> BashPowerShell <pre><code>echo \"Hello bash 2!\"\n</code></pre> <pre><code>Write-Host \"Hello PowerShell 2!\"\n</code></pre>"},{"location":"documentation/mkdocs/#data-tables","title":"Data tables","text":"Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource"},{"location":"documentation/mkdocs/#diagrams","title":"Diagrams","text":"<p>Example-1:</p> <pre><code>graph TD\n    A[Hard] --&gt;|Text| B(Round)\n    B --&gt; C{Decision}\n    C --&gt;|One| D[Result 1]\n    C --&gt;|Two| E[Result 2]</code></pre> <p>Example-2:</p> <pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre>"},{"location":"documentation/mkdocs/#grids","title":"Grids","text":"<ul> <li> HTML for content and structure</li> <li> JavaScript for interactivity</li> <li> CSS for text running out of boxes</li> <li> Internet Explorer ... huh?</li> </ul>"},{"location":"documentation/mkdocs/#icons-and-emojis","title":"Icons and Emojis","text":"<ul> <li>Material for MkDocs / References / Icons, Emojis</li> </ul>"},{"location":"documentation/mkdocs/#images","title":"Images","text":"<p>Blue clouds under white sky photo. Credit: CHUTTERSNAP</p> <p> </p> Cumulus clouds under blue sky photo. Credit: [Anton Darius](https://unsplash.com/photos/cumulus-clouds-under-blue-sky-15AMBS1gM2E)"},{"location":"documentation/mkdocs/#lists","title":"Lists","text":"<ul> <li> item 1</li> <li> item B         more text<ul> <li> item a</li> <li> item b</li> </ul> </li> <li> item 2</li> </ul>"},{"location":"documentation/mkdocs/#tooltips","title":"Tooltips","text":""},{"location":"documentation/starlight/","title":"\ud83c\udf1f Starlight","text":"<p>Tool to create documentation websites with Astro. Starlight</p>"},{"location":"infrastructure/infrastructure/","title":"Infrastructure","text":"<ul> <li>Shift FinOps Left With Infracost</li> </ul>"},{"location":"python/scheduled-task/","title":"Twitter checks","text":"<ul> <li>Gmail</li> <li>Twitter API</li> <li>Platforms</li> <li>GitHub Actions</li> <li>PythonAnywhere</li> </ul>"},{"location":"python/scheduled-task/#gmail","title":"Gmail","text":"<ul> <li>Quick Tip: Sending Email via Gmail with Python</li> <li>SMTP for free users</li> <li>Sign in with app passwords</li> <li>Google</li> </ul> <p>Go to: Google Account &gt; Security &gt; 2-Step Verification &gt; App passwords. The App password will look like <code>aaaa aaaa aaaa aaaa</code>.</p>"},{"location":"python/scheduled-task/#twitter-api","title":"Twitter API","text":"<ul> <li>Twitter - Developer Portal</li> <li>Project &amp; App: <code>twitter-nickname</code></li> <li>Authentication Tokens (Bearer Token): <code>AAAAAAAAAAAAAAAAAAAAA</code></li> </ul>"},{"location":"python/scheduled-task/#platforms","title":"Platforms","text":"<p>Platform to schdule the task for free:</p> <ul> <li>Python Free Hosts</li> <li>PythonAnywhere</li> <li>GitHub Actions</li> </ul>"},{"location":"python/scheduled-task/#github-actions","title":"GitHub Actions","text":""},{"location":"python/scheduled-task/#pythonanywhere","title":"PythonAnywhere","text":"<ul> <li>PythonAnywhere Overview</li> <li>How to set environment variables for your web apps (for SECRET_KEY etc)</li> <li>Scheduled tasks</li> <li>Installing new modules</li> </ul> <pre><code>python --version # Python 3.10.5\npip --version # pip 22.2 from /usr/local/lib/python3.10/site-packages/pip (python 3.10)\npip3.10 --version # pip 22.2 from /usr/local/lib/python3.10/site-packages/pip (python 3.10)\npip install --user python-dotenv\n\ncd /home/mitru/twitter_nickname/\necho \"export TWITTER_BEARER_TOKEN=AAAAAAAAAAAAAAAAAAAAA\" &gt;&gt; .env\necho \"export GMAIL_APP_PASSWORD=aaaa aaaa aaaa aaaa\" &gt;&gt; .env\ncat .env\n</code></pre>"}]}